{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCT Compression:\n",
      "Compression Ratio: 1.00\n",
      "RMSE: 2.41\n",
      "\n",
      "Huffman Compression:\n",
      "Compression Ratio: 1.44\n",
      "RMSE: 0.00\n",
      "\n",
      "LZW Compression:\n",
      "Compression Ratio: 2.17\n",
      "RMSE: 0.00\n",
      "\n",
      "RLE Compression:\n",
      "Compression Ratio: 1.07\n",
      "RMSE: 0.00\n",
      "\n",
      "Arithmetic Compression:\n",
      "Compression Ratio: 0.18\n",
      "RMSE: 0.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.fftpack import dct, idct\n",
    "from PIL import Image\n",
    "import heapq\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import struct\n",
    "\n",
    "def dct_compression(image, quality_factor=30):\n",
    "    \"\"\"Transform Coding using DCT with improved compression\"\"\"\n",
    "    height, width = image.shape\n",
    "    block_size = 8\n",
    "    compressed_data = []\n",
    "    \n",
    "    for i in range(0, height, block_size):\n",
    "        for j in range(0, width, block_size):\n",
    "            block = image[i:i+block_size, j:j+block_size]\n",
    "            if block.shape[0] != block_size or block.shape[1] != block_size:\n",
    "                padded = np.zeros((block_size, block_size))\n",
    "                padded[:block.shape[0], :block.shape[1]] = block\n",
    "                block = padded\n",
    "            \n",
    "            dct_block = dct(dct(block.T, norm='ortho').T, norm='ortho')\n",
    "            q_matrix = np.ones((block_size, block_size)) * quality_factor\n",
    "            q_matrix[0:4, 0:4] = quality_factor // 2\n",
    "            \n",
    "            quantized = np.round(dct_block / q_matrix)\n",
    "            compressed_data.append(quantized)\n",
    "    \n",
    "    reconstructed = np.zeros_like(image)\n",
    "    block_idx = 0\n",
    "    \n",
    "    for i in range(0, height, block_size):\n",
    "        for j in range(0, width, block_size):\n",
    "            dct_block = compressed_data[block_idx] * q_matrix\n",
    "            block = idct(idct(dct_block.T, norm='ortho').T, norm='ortho')\n",
    "            h = min(block_size, height-i)\n",
    "            w = min(block_size, width-j)\n",
    "            reconstructed[i:i+h, j:j+w] = block[:h, :w]\n",
    "            block_idx += 1\n",
    "    \n",
    "    return np.uint8(np.clip(reconstructed, 0, 255))\n",
    "\n",
    "def huffman_encoding(image):\n",
    "    \"\"\"Huffman Encoding with chunk processing\"\"\"\n",
    "    def chunks(data, size=1024):\n",
    "        for i in range(0, len(data), size):\n",
    "            yield data[i:i+size]\n",
    "    \n",
    "    frequencies = defaultdict(int)\n",
    "    for pixel in image.flatten():\n",
    "        frequencies[pixel] += 1\n",
    "    \n",
    "    heap = [[freq, [pixel, \"\"]] for pixel, freq in frequencies.items()]\n",
    "    heapq.heapify(heap)\n",
    "    \n",
    "    while len(heap) > 1:\n",
    "        lo = heapq.heappop(heap)\n",
    "        hi = heapq.heappop(heap)\n",
    "        for pair in lo[1:]:\n",
    "            pair[1] = '0' + pair[1]\n",
    "        for pair in hi[1:]:\n",
    "            pair[1] = '1' + pair[1]\n",
    "        heapq.heappush(heap, [lo[0] + hi[0]] + lo[1:] + hi[1:])\n",
    "    \n",
    "    huffman_dict = dict(heap[0][1:])\n",
    "    \n",
    "    # Process in chunks\n",
    "    encoded_bytes = bytearray()\n",
    "    current_byte = 0\n",
    "    bit_count = 0\n",
    "    \n",
    "    for chunk in chunks(image.flatten()):\n",
    "        for pixel in chunk:\n",
    "            code = huffman_dict[pixel]\n",
    "            for bit in code:\n",
    "                current_byte = (current_byte << 1) | (1 if bit == '1' else 0)\n",
    "                bit_count += 1\n",
    "                if bit_count == 8:\n",
    "                    encoded_bytes.append(current_byte)\n",
    "                    current_byte = 0\n",
    "                    bit_count = 0\n",
    "    \n",
    "    # Handle remaining bits\n",
    "    if bit_count > 0:\n",
    "        current_byte = current_byte << (8 - bit_count)\n",
    "        encoded_bytes.append(current_byte)\n",
    "    \n",
    "    return encoded_bytes, (huffman_dict, bit_count, image.shape)\n",
    "\n",
    "def lzw_encoding(image):\n",
    "    \"\"\"LZW Encoding with chunk processing\"\"\"\n",
    "    chunk_size = 1024\n",
    "    dictionary = {bytes([i]): i for i in range(256)}\n",
    "    dictionary_size = 256\n",
    "    compressed = bytearray()\n",
    "    \n",
    "    def encode_chunk(chunk):\n",
    "        nonlocal dictionary_size\n",
    "        current = bytes([chunk[0]])\n",
    "        result = bytearray()\n",
    "        \n",
    "        for byte in chunk[1:]:\n",
    "            byte = bytes([byte])\n",
    "            temp = current + byte\n",
    "            if temp in dictionary:\n",
    "                current = temp\n",
    "            else:\n",
    "                result.extend(dictionary[current].to_bytes(2, byteorder='big'))\n",
    "                if dictionary_size < 65536:\n",
    "                    dictionary[temp] = dictionary_size\n",
    "                    dictionary_size += 1\n",
    "                current = byte\n",
    "        \n",
    "        if current:\n",
    "            result.extend(dictionary[current].to_bytes(2, byteorder='big'))\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    # Process image in chunks\n",
    "    data = image.tobytes()\n",
    "    for i in range(0, len(data), chunk_size):\n",
    "        chunk = data[i:i+chunk_size]\n",
    "        compressed.extend(encode_chunk(chunk))\n",
    "    \n",
    "    return compressed, image.shape\n",
    "\n",
    "def rle_encoding(image):\n",
    "    \"\"\"RLE with chunk processing\"\"\"\n",
    "    chunk_size = 1024\n",
    "    encoded = bytearray()\n",
    "    \n",
    "    def encode_chunk(chunk):\n",
    "        result = bytearray()\n",
    "        count = 1\n",
    "        current = chunk[0]\n",
    "        \n",
    "        for pixel in chunk[1:]:\n",
    "            if pixel == current and count < 255:\n",
    "                count += 1\n",
    "            else:\n",
    "                result.append(count)\n",
    "                result.append(current)\n",
    "                count = 1\n",
    "                current = pixel\n",
    "        \n",
    "        result.append(count)\n",
    "        result.append(current)\n",
    "        return result\n",
    "    \n",
    "    # Process image in chunks\n",
    "    flat_image = image.flatten()\n",
    "    for i in range(0, len(flat_image), chunk_size):\n",
    "        chunk = flat_image[i:i+chunk_size]\n",
    "        encoded.extend(encode_chunk(chunk))\n",
    "    \n",
    "    return encoded, image.shape\n",
    "\n",
    "def arithmetic_encoding(image):\n",
    "    \"\"\"Arithmetic Encoding with reduced precision\"\"\"\n",
    "    PRECISION = 16  # Reduced precision to avoid overflow\n",
    "    ONE = 2 ** PRECISION\n",
    "    HALF = ONE >> 1\n",
    "    QUARTER = HALF >> 1\n",
    "    \n",
    "    frequencies = defaultdict(int)\n",
    "    total = 0\n",
    "    for symbol in image.flatten():\n",
    "        frequencies[symbol] += 1\n",
    "        total += 1\n",
    "    \n",
    "    cumul = {}\n",
    "    acc = 0\n",
    "    for symbol in sorted(frequencies):\n",
    "        cumul[symbol] = (acc, acc + frequencies[symbol])\n",
    "        acc += frequencies[symbol]\n",
    "    \n",
    "    low, high = 0, ONE\n",
    "    encoded = bytearray()\n",
    "    bits_to_follow = 0  # Initialize bits_to_follow here\n",
    "    \n",
    "    def output_bit(bit):\n",
    "        nonlocal encoded, bits_to_follow  # Add bits_to_follow to nonlocal declaration\n",
    "        encoded.append(bit)\n",
    "        while bits_to_follow > 0:\n",
    "            encoded.append(1 - bit)\n",
    "            bits_to_follow -= 1\n",
    "    \n",
    "    # Process each symbol\n",
    "    for symbol in image.flatten():\n",
    "        range_size = high - low\n",
    "        high = low + (range_size * cumul[symbol][1]) // total\n",
    "        low = low + (range_size * cumul[symbol][0]) // total\n",
    "        \n",
    "        while True:\n",
    "            if high < HALF:\n",
    "                output_bit(0)\n",
    "            elif low >= HALF:\n",
    "                output_bit(1)\n",
    "                low -= HALF\n",
    "                high -= HALF\n",
    "            elif low >= QUARTER and high < 3*QUARTER:\n",
    "                bits_to_follow += 1\n",
    "                low -= QUARTER\n",
    "                high -= QUARTER\n",
    "            else:\n",
    "                break\n",
    "            low *= 2\n",
    "            high *= 2\n",
    "            if low >= ONE:\n",
    "                low -= ONE\n",
    "            if high >= ONE:\n",
    "                high -= ONE\n",
    "    \n",
    "    # Output final bits\n",
    "    bits_to_follow += 1\n",
    "    if low < QUARTER:\n",
    "        output_bit(0)\n",
    "    else:\n",
    "        output_bit(1)\n",
    "    \n",
    "    return encoded, (frequencies, total, image.shape)\n",
    "\n",
    "def calculate_metrics(original, compressed_size):\n",
    "    \"\"\"Calculate Compression Ratio\"\"\"\n",
    "    original_size = original.nbytes\n",
    "    return original_size / compressed_size\n",
    "\n",
    "def main():\n",
    "    # Load image\n",
    "    image = np.array(Image.open('image.png').convert('L'))\n",
    "    \n",
    "    # Test compressions\n",
    "    reconstructed_dct = dct_compression(image)\n",
    "    cr_dct = calculate_metrics(image, reconstructed_dct.nbytes)\n",
    "    rmse_dct = np.sqrt(np.mean((image - reconstructed_dct) ** 2))\n",
    "    \n",
    "    compressed_huff, _ = huffman_encoding(image)\n",
    "    cr_huff = calculate_metrics(image, len(compressed_huff))\n",
    "    \n",
    "    compressed_lzw, _ = lzw_encoding(image)\n",
    "    cr_lzw = calculate_metrics(image, len(compressed_lzw))\n",
    "    \n",
    "    compressed_rle, _ = rle_encoding(image)\n",
    "    cr_rle = calculate_metrics(image, len(compressed_rle))\n",
    "    \n",
    "    compressed_arith, _ = arithmetic_encoding(image)\n",
    "    cr_arith = calculate_metrics(image, len(compressed_arith))\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"DCT Compression:\")\n",
    "    print(f\"Compression Ratio: {cr_dct:.2f}\")\n",
    "    print(f\"RMSE: {rmse_dct:.2f}\\n\")\n",
    "    \n",
    "    print(f\"Huffman Compression:\")\n",
    "    print(f\"Compression Ratio: {cr_huff:.2f}\")\n",
    "    print(f\"RMSE: 0.00\\n\")\n",
    "    \n",
    "    print(f\"LZW Compression:\")\n",
    "    print(f\"Compression Ratio: {cr_lzw:.2f}\")\n",
    "    print(f\"RMSE: 0.00\\n\")\n",
    "    \n",
    "    print(f\"RLE Compression:\")\n",
    "    print(f\"Compression Ratio: {cr_rle:.2f}\")\n",
    "    print(f\"RMSE: 0.00\\n\")\n",
    "    \n",
    "    print(f\"Arithmetic Compression:\")\n",
    "    print(f\"Compression Ratio: {cr_arith:.2f}\")\n",
    "    print(f\"RMSE: 0.00\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
